{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_Part_1_low_level_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaileshaPMaganahalli/CMPE_297_Advanced_Deep_Learning/blob/master/Assignment_2/Assignment_2_Part_1_low_level_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX1Vg6-K5Cxj"
      },
      "source": [
        "## Shailesha Assignment_2 and Part_1 gradient tape and low level tensorflow code for linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmFYGK_S4iHM"
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CsaEcP05MrS"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wyM-dkT5toQ"
      },
      "source": [
        "a = tf.random.normal(shape =(3,3))\n",
        "b = tf.random.normal(shape =(3,3))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(a)\n",
        "  c = tf.sqrt(tf.sqrt(a)+tf.square(a)+b)\n",
        "  c_a = tape.gradient(c,a)\n",
        "  print(c_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rls5Oao07WbB"
      },
      "source": [
        "# Linear regression using Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVR0wrZG7CLd"
      },
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "# weight matrix and bias\n",
        "w = tf.Variable(tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1R3slPmK5Cn"
      },
      "source": [
        "Prediction function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJiIuJYLKvgt"
      },
      "source": [
        "def prediction(features):\n",
        "  return tf.matmul(features,w)+b\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHvDs3ZhK8PW"
      },
      "source": [
        "loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpbCpnoZKybQ"
      },
      "source": [
        "def lossfn(labels, predictions):\n",
        "  return tf.reduce_mean(tf.square(labels - predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOo-9TsLEqU"
      },
      "source": [
        "Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSER3KdBKz32"
      },
      "source": [
        "def training(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = prediction(x)\n",
        "      loss = lossfn(y, predictions)\n",
        "      dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "    w.assign_sub(learning_rate * dloss_dw)\n",
        "    b.assign_sub(learning_rate * dloss_db)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNN-QmSGLLFl"
      },
      "source": [
        "Artificial data to test the linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBQBLHAUSHPv"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTUMls67LQCg"
      },
      "source": [
        "num_samples = 10000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 10], cov=[[1, 0.75],[0.75, 1]], size=num_samples)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[10, 0], cov=[[1, 0.75],[0.75, 1]], size=num_samples)\n",
        "features = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "labels = np.vstack((np.zeros((num_samples, 1), dtype='float32'),\n",
        "                    np.ones((num_samples, 1), dtype='float32')))\n",
        "\n",
        "plt.scatter(features[:, 0], features[:, 1], c=labels[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ahNzP5_Tv1_"
      },
      "source": [
        "indices = np.random.permutation(len(features))\n",
        "features = features[indices]\n",
        "\n",
        "labels = labels[indices]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(256)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF9JsUa0T4pa"
      },
      "source": [
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = training(x, y)\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
        "\n",
        "predictions = prediction(features)\n",
        "plt.scatter(features[:, 0], features[:, 1], c=predictions[:, 0] > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdgaklP_VFkD"
      },
      "source": [
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = training(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('Time per epoch: %.3f s' % (t_end / 20,))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAffUnBeVbIJ"
      },
      "source": [
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = compute_predictions(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1HC57paVjD7"
      },
      "source": [
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = training(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('Time per epoch: %.3f s' % (t_end / 20,))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}